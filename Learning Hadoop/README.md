## Instructor: Lynn Langit
LinkedIn Profile: https://www.linkedin.com/in/lynnlangit/?trk=lil_instructor

## Course Description
Hadoop is indispensible when it comes to processing big dataâ€”as necessary to understanding your information as servers are to storing it. This course is your introduction to Hadoop, its file system (HDFS), its processing engine (MapReduce), and its many libraries and programming tools. Developer and big-data consultant Lynn Langit shows how to set up a Hadoop development environment, run and optimize MapReduce jobs, code basic queries with Hive and Pig, and build workflows to schedule jobs. Plus, get a sneak peek at some up-and-coming libraries like Impala and the lightning-fast Spark.

## Learning Objectives
- Understanding Hadoop core components: HDFS and MapReduce
- Setting up your Hadoop development environment
- Working with the Hadoop file system
- Running and tracking Hadoop jobs
- Tuning MapReduce
- Understanding Hive and HBase
- Exploring Pig tools
- Building workflows
- Using other libraries, such as Impala, Mahout, and Storm
- Understanding Spark
- Visualizing Hadoop output

## Skills Covered
- Hadoop
- Databases
- Database Development
- Apache

